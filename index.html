<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Li Xiao (李潇)</title> <meta name="author" content="Li Xiao"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://lixiaothu.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/me-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/me-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/me-1400.webp"></source> <img src="/assets/img/me.png?9361274b2b7ad11edef4e3b4e41a85ca" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="me.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div> <h1 class="post-title"> Li Xiao (李潇) </h1> <p class="desc">Ph.D. student at the Department of Computer Science and Technology, Tsinghua University.</p> </div> <div class="clearfix"> <p>  <a href="mailto:%6C%69%78%69%61%6F%32%30@%6D%61%69%6C%73.%74%73%69%6E%67%68%75%61.%65%64%75.%63%6E" title="email"><i class="fas fa-envelope"></i></a> lixiao20@mails.tsinghua.edu.cn; xiaoli.cst@gmail.com <br>   <a href="https://scholar.google.com/citations?user=Is24dqwAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://scholar.google.com/citations?user=Is24dqwAAAAJ" rel="external nofollow noopener" target="_blank">Google Scholar</a>   <a href="https://github.com/LixiaoTHU" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://github.com/LixiaoTHU" rel="external nofollow noopener" target="_blank">Github</a></p> <p>  <span style="color: red;">I am looking for a full-time position in industry or academia. Feel free to reach out to me!</span></p> <p>Affiliation:<br>  <a href="https://www.cs.tsinghua.edu.cn/csen/" rel="external nofollow noopener" target="_blank">Department of Computer Science and Technology</a>,<br>  <a href="http://www.csai.tsinghua.edu.cn/" rel="external nofollow noopener" target="_blank">State Key Laboratory of Intelligent Technology and Systems (CSAI)</a>,<br>  <a href="https://www.tsinghua.edu.cn/en/" rel="external nofollow noopener" target="_blank">Tsinghua University</a>, Beijing 100084, China;<br>  <a href="https://brain.tsinghua.edu.cn/" rel="external nofollow noopener" target="_blank">Tsinghua Laboratory of Brain and Intelligence (THBI)</a>;<br>  <a href="http://mcgovern.life.tsinghua.edu.cn/en" rel="external nofollow noopener" target="_blank">IDG/McGovern Institute for Brain Research at Tsinghua</a>.</p> <hr> <p>I am a Ph.D. student at the <a href="https://www.cs.tsinghua.edu.cn/csen/" rel="external nofollow noopener" target="_blank">Department of Computer Science and Technology</a> in <a href="https://www.tsinghua.edu.cn/en/" rel="external nofollow noopener" target="_blank">Tsinghua University</a>, advised by <a href="http://xlhu.cn/" rel="external nofollow noopener" target="_blank">Prof. Xiaolin Hu</a> and <a href="https://www.cs.tsinghua.edu.cn/csen/info/1059/4006.htm" rel="external nofollow noopener" target="_blank">Prof. Bo Zhang</a>. I am a member of <a href="https://ml.cs.tsinghua.edu.cn/" rel="external nofollow noopener" target="_blank">TSAIL Group</a>, which is directed by <a href="https://www.cs.tsinghua.edu.cn/csen/info/1059/4006.htm" rel="external nofollow noopener" target="_blank">Prof. Bo Zhang</a> and <a href="https://ml.cs.tsinghua.edu.cn/~jun/index.shtml" rel="external nofollow noopener" target="_blank">Prof. Jun Zhu</a>. I received my Bachelor’s degree at Department of Computer Science and Technology from <a href="https://www.tsinghua.edu.cn/en/" rel="external nofollow noopener" target="_blank">Tsinghua University</a> in 2020.</p> <p>My research interests lie at the intersection of computer vision (CV) and machine learning (ML), with the goal of developing trustworthy multimodal computer vision systems that can achieve human‐level visual understanding and out-of-distribution (OOD) generalization. I have explored the following areas:</p> <li> <b>Classical CV applications</b>: Improving the accuracy and robustness of general object detection, instance segmentation, and other tasks. </li> <li> <b>Visual-language multimodal learning</b>: Exploring potential issues and solutions for aligning multimodal models on OOD samples. </li> <li> <b>Diffusion models</b>: Enhancing the OOD generalization of visual models by leveraging the ability of diffusion models. </li> <li> <b>Large language models</b>: Investigating potential security risks of large language models, establishing efficient jailbreak attacks and defense methods for large language models. </li> <li> <b>Trustworthy machine learning</b>: Exploring frontier problems such as federated learning, adversarial ML, and ML privacy. </li> </div> <h2><a href="/news/" style="color: inherit;">news</a></h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Aug 1, 2024</th> <td> We propose the ADBM model, which can significantly improves the robustness of visual models on OOD examples. We show theoretically and empirically that ADBM outperform the original DDPM. This work is now available on arXiv. <a href="https://arxiv.org/abs/2408.00315" rel="external nofollow noopener" target="_blank">Read more</a> </td> </tr> <tr> <th scope="row">Jul 7, 2024</th> <td> We released the PartImageNet++ dataset and further improved the part-based recogntion models. The paper has been accepted by <strong>ECCV 2024</strong>. <a href="https://arxiv.org/abs/2407.10918" rel="external nofollow noopener" target="_blank">Read more</a> </td> </tr> <tr> <th scope="row">Mar 18, 2024</th> <td> One paper on the relation between adversarial robustness and privacy is accepted by <strong>IEEE TIFS 2024</strong>. <a href="https://ieeexplore.ieee.org/abstract/document/10478637/" rel="external nofollow noopener" target="_blank">Read more</a> </td> </tr> <tr> <th scope="row">Feb 26, 2024</th> <td> One paper on achiving zero-shot adversarial robustness with multimodal CLIP models is accepted by <strong>CVPR 2024</strong>. The proposed LAAT method uses language-driven anchors to guide adversarial training of vision models. <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Li_Language-Driven_Anchors_for_Zero-Shot_Adversarial_Robustness_CVPR_2024_paper.pdf" rel="external nofollow noopener" target="_blank">Read more</a> </td> </tr> <tr> <th scope="row">May 27, 2023</th> <td> One paper on how to improving robustness of object detectors with upstream adversarial pre-training is available on arXiv. <a href="https://arxiv.org/abs/2305.17438" rel="external nofollow noopener" target="_blank">Read more</a> </td> </tr> <tr> <th scope="row">Jan 18, 2023</th> <td> One paper inspired by cognitive psychology theory is accepted by <strong>IEEE TPAMI 2023</strong>. The proposed ROCK method can significantly improve both adversarial robusntess and generalization on out-of-distribution examples. <a href="https://ieeexplore.ieee.org/abstract/document/10019576" rel="external nofollow noopener" target="_blank">Read more</a> </td> </tr> <tr> <th scope="row">Jul 14, 2022</th> <td> One paper is accepted by <strong>IJCV 2022</strong>, which is an extended version of the BPR paper. <a href="https://link.springer.com/article/10.1007/s11263-022-01662-0" rel="external nofollow noopener" target="_blank">Read more</a> </td> </tr> <tr> <th scope="row">Mar 1, 2021</th> <td> One paper on instance segmentatiion is accepted to <strong>CVPR 2021</strong>. The proposed BPR method reached <strong>1st place</strong> on the Cityscapes leaderboard (instance segmentation track). <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Tang_Look_Closer_To_Segment_Better_Boundary_Patch_Refinement_for_Instance_CVPR_2021_paper.pdf" rel="external nofollow noopener" target="_blank">Read more</a> </td> </tr> </table> </div> </div> <h2><a href="/publications/" style="color: inherit;">selected publications</a></h2> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-1"><div class="abbr"><abbr class="badge">ECCV</abbr></div></div> <div id="lipartimagenetpp" class="col-sm-7"> <a href="https://arxiv.org/pdf/2407.10918.pdf" rel="external nofollow noopener" target="_blank"> <div class="title">PartImageNet++ Dataset: Scaling up Part-based Models for Robust Recognition</div> </a> <div class="author"> <em>Xiao Li</em>, Yining Liu, Na Dong, Sitian Qin, and Xiaolin Hu</div> <div class="periodical"> <em>European Conference on Computer Vision (ECCV)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://arxiv.org/abs/2407.10918" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/LixiaoTHU/PartImageNetPP" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">lipartimagenetpp</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{PartImageNet++ Dataset: Scaling up Part-based Models for Robust Recognition}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Xiao and Liu, Yining and Dong, Na and Qin, Sitian and Hu, Xiaolin}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{European Conference on Computer Vision (ECCV)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-4 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/pinpp-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/pinpp-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/pinpp-1400.webp"></source> <img src="/assets/img/publication_preview/pinpp.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="pinpp.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> </li> <li> <div class="row"> <div class="col-sm-1"><div class="abbr"><abbr class="badge">arXiv</abbr></div></div> <div id="li2024adbm" class="col-sm-7"> <a href="https://arxiv.org/pdf/2408.00315.pdf" rel="external nofollow noopener" target="_blank"> <div class="title">ADBM: Adversarial diffusion bridge model for reliable adversarial purification</div> </a> <div class="author"> <em>Xiao Li</em>, Wenxuan Sun, Huanran Chen, Qiongxiu Li, Yining Liu, Yingzhe He, Jie Shi, and Xiaolin Hu</div> <div class="periodical"> <em>arXiv preprint arXiv:2408.00315</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://arxiv.org/abs/2408.00315" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">li2024adbm</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ADBM: Adversarial diffusion bridge model for reliable adversarial purification}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Xiao and Sun, Wenxuan and Chen, Huanran and Li, Qiongxiu and Liu, Yining and He, Yingzhe and Shi, Jie and Hu, Xiaolin}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2408.00315}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-4 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/adbm-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/adbm-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/adbm-1400.webp"></source> <img src="/assets/img/publication_preview/adbm.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="adbm.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> </li> <li> <div class="row"> <div class="col-sm-1"><div class="abbr"><abbr class="badge">CVPR</abbr></div></div> <div id="li2023languagedriven" class="col-sm-7"> <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Li_Language-Driven_Anchors_for_Zero-Shot_Adversarial_Robustness_CVPR_2024_paper.pdf" rel="external nofollow noopener" target="_blank"> <div class="title">Language-Driven Anchors for Zero-Shot Adversarial Robustness</div> </a> <div class="author"> <em>Xiao Li</em>, Wei Zhang, Yining Liu, Zhanhao Hu, Bo Zhang, and Xiaolin Hu</div> <div class="periodical"> <em>In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://arxiv.org/abs/2301.13096" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/LixiaoTHU/LAAT" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">li2023languagedriven</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Xiao and Zhang, Wei and Liu, Yining and Hu, Zhanhao and Zhang, Bo and Hu, Xiaolin}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Language-Driven Anchors for Zero-Shot Adversarial Robustness}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{24686--24695}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-4 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/laat-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/laat-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/laat-1400.webp"></source> <img src="/assets/img/publication_preview/laat.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="laat.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-1"><div class="abbr"><abbr class="badge">TPAMI</abbr></div></div> <div id="rock" class="col-sm-7"> <a href="https://ieeexplore.ieee.org/abstract/document/10019576" rel="external nofollow noopener" target="_blank"> <div class="title">Recognizing Object by Components With Human Prior Knowledge Enhances Adversarial Robustness of Deep Neural Networks</div> </a> <div class="author"> <em>Xiao Li</em>, Ziqi Wang, Bo Zhang, Fuchun Sun, and Xiaolin Hu</div> <div class="periodical"> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://arxiv.org/abs/2212.01806" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/LixiaoTHU/ROCK" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">rock</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Xiao and Wang, Ziqi and Zhang, Bo and Sun, Fuchun and Hu, Xiaolin}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Recognizing Object by Components With Human Prior Knowledge Enhances
                    Adversarial Robustness of Deep Neural Networks}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{{IEEE} Transactions on Pattern Analysis and Machine Intelligence (TPAMI)}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{45}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{8861--8873}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure> </div> </div> <div class="col-sm-4 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/rock-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/rock-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/rock-1400.webp"></source> <img src="/assets/img/publication_preview/rock.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="rock.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> </li></ol> </div> </article> </header> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Li Xiao. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>